{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Unreasonable Effectiveness of Character-level Language Models\n",
    "# (and why RNNs are still cool)\n",
    "\n",
    "## By [Yoav Goldberg](http://www.cs.biu.ac.il/~yogo) (2015)\n",
    "\n",
    "#### (with minor changes by Peter Norvig (2022) for modern Python 3)\n",
    "\n",
    "<hr>\n",
    "\n",
    "[RNNs](https://en.wikipedia.org/wiki/Recurrent_neural_network), [LSTMs](https://en.wikipedia.org/wiki/Long_short-term_memory) and [Deep Learning](https://en.wikipedia.org/wiki/Deep_learning) are all the rage, and a recent [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy is doing a great job explaining what these models are and how to train them.\n",
    "It also provides some very impressive results of what they are capable of.  This is a great post, and if you are interested in natural language, machine learning or neural networks you should definitely read it. \n",
    "\n",
    "Go [**read it now**](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), then come back here. \n",
    "\n",
    "You're back? Good. Impressive stuff, huh? How could the network learn to imitate the input like that?\n",
    "Indeed. I was quite impressed as well.\n",
    "\n",
    "However, it feels to me that most readers of the post are impressed by the wrong reasons.\n",
    "This is because they are not familiar with **unsmoothed maximum-liklihood character level language models** and their unreasonable effectiveness at generating rather convincing natural language outputs.\n",
    "\n",
    "In what follows I will briefly describe these character-level maximum-likelihood langauge models, which are much less magical than RNNs and LSTMs, and show that they too can produce a rather convincing Shakespearean prose. I will also show about 30 lines of python code that take care of both training the model and generating the output. Compared to this baseline, the RNNs may seem somehwat less impressive. So why was I impressed? I will explain this too, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsmoothed Maximum Likelihood Character Level Language Model \n",
    "\n",
    "The name is quite long, but the idea is very simple.  We want a model whose job is to guess the next character based on the previous *n* letters. For example, having seen `ello`, the next characer is likely to be either a commma or space (if we assume is is the end of the word \"hello\"), or the letter `w` if we believe we are in the middle of the word \"mellow\". Humans are quite good at this, but of course seeing a larger history makes things easier (if we were to see 5 letters instead of 4, the choice between space and `w` would have been much easier).\n",
    "\n",
    "We will call *n*, the number of letters we need to guess based on, the _order_ of the language model.\n",
    "\n",
    "RNNs and LSTMs can potentially learn infinite-order language model (they guess the next character based on a \"state\" which supposedly encode all the previous history). We here will restrict ourselves to a fixed-order language model.\n",
    "\n",
    "So, we are seeing *n* letters, and need to guess the *n+1*th one. We are also given a large-ish amount of text (say, all of Shakespear works) that we can use. How would we go about solving this task?\n",
    "\n",
    "Mathematically, we would like to learn a function *P(c* | *h)*. Here, *c* is a character, *h* is a *n*-letters history, and *P(c* | *h)* stands for how likely is it to see *c* after we've seen *h*.\n",
    "\n",
    "Perhaps the simplest approach would be to just count and divide (a.k.a **maximum likelihood estimates**). We will count the number of times each letter *c* appeared after *h*, and divide by the total numbers of letters appearing after *h*. The **unsmoothed** part means that if we did not see a given letter following *h*, we will just give it a probability of zero.\n",
    "\n",
    "And that's all there is to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code\n",
    "\n",
    "Here is the code for training a language model, which implements *P(c* | *h)* with a counter of the number of times we have seen each character, for each history. The function `train_char_lm` takes a filename  to read the characters from. `order` is the history size to consult. Note that we pad the data with `order` leading characters so that we also learn how to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(collections.defaultdict):\n",
    "    \"\"\"A mapping from `order` history characters to a Counter of {'c': count} pairs,\n",
    "    e.g., for order=4, {'spea': Counter({'k': 9, 'r': 1})}.\"\"\"\n",
    "    def __init__(self, order): \n",
    "        self.order = order\n",
    "        self.default_factory = collections.Counter \n",
    "\n",
    "def train_char_lm(fname, order=4) -> LanguageModel:\n",
    "    \"\"\"Train an `order`-gram character-level language model on all the text in `fname`.\"\"\"\n",
    "    lm = LanguageModel(order)\n",
    "    data = (order * PAD) + open(fname).read()\n",
    "    for i in range(order, len(data)):\n",
    "        history, char = data[i - order:i], data[i]\n",
    "        lm[history][char] += 1\n",
    "    for counter in lm.values():\n",
    "        counter.total = sum(counter.values()) # Cache total counts (for sample_character)\n",
    "    return lm\n",
    "\n",
    "PAD = '`' # Character to pad the beginning of a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it on Andrej's Shakespeare text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  167204  832301 4573338 shakespeare_input.txt\n"
     ]
    }
   ],
   "source": [
    "! [ -f shakespeare_input.txt ] || curl -O https://norvig.com/ngrams/shakespeare_input.txt\n",
    "! wc shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Now let's do some queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'r': 35,\n",
       "         'w': 480,\n",
       "         'u': 22,\n",
       "         ',': 16,\n",
       "         ' ': 8,\n",
       "         '.': 4,\n",
       "         '?': 4,\n",
       "         ':': 3,\n",
       "         'n': 1,\n",
       "         \"'\": 10,\n",
       "         '!': 4})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['ello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'t': 864})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['Firs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'C': 119,\n",
       "         'f': 14,\n",
       "         'i': 21,\n",
       "         't': 67,\n",
       "         'u': 2,\n",
       "         'S': 203,\n",
       "         'h': 24,\n",
       "         's': 41,\n",
       "         'R': 1,\n",
       "         'b': 31,\n",
       "         'c': 16,\n",
       "         'O': 23,\n",
       "         'w': 30,\n",
       "         'a': 28,\n",
       "         'm': 28,\n",
       "         'n': 25,\n",
       "         'I': 12,\n",
       "         'L': 133,\n",
       "         'M': 74,\n",
       "         'l': 13,\n",
       "         'o': 38,\n",
       "         'H': 5,\n",
       "         'd': 19,\n",
       "         'W': 42,\n",
       "         'K': 10,\n",
       "         'q': 2,\n",
       "         'G': 112,\n",
       "         'g': 14,\n",
       "         'k': 5,\n",
       "         'e': 4,\n",
       "         'y': 3,\n",
       "         'r': 9,\n",
       "         'p': 11,\n",
       "         'A': 7,\n",
       "         'P': 18,\n",
       "         'F': 15,\n",
       "         'v': 3,\n",
       "         'T': 4,\n",
       "         'D': 4,\n",
       "         'B': 12,\n",
       "         'N': 1,\n",
       "         \"'\": 1,\n",
       "         'E': 2})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['rst ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `\"ello\"` is followed by either space, punctuation or `w` (or `r`, `u`, `n`), `\"Firs\"` is pretty much deterministic, and the word following `\"rst \"` can start with pretty much every letter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating from the model\n",
    "\n",
    "To generate a random text from a model, we maintain a history of *order* characters, which starts with all pad characters. We then enter a loop that randomly samples a character from the history's counter, then updates the history by dropping its first character and adding the randomly-sampled character to the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lm, length=1000) -> str:\n",
    "    \"\"\"Sample a random `length`-long passage from `lm`.\"\"\"\n",
    "    history = lm.order * PAD\n",
    "    text = []\n",
    "    for _ in range(length):\n",
    "        c = sample_character(lm[history])\n",
    "        history = history[1:] + c\n",
    "        text.append(c)\n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample a single character from a counter, randomly choose an integer *n* from 1 to the total count of characters in the counter, then iterate through (character, count) items until the cumulative total of the counts meets or exceeds *n*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_character(counter) -> str:\n",
    "    \"\"\"Randomly sample the nth character from the counter.\"\"\"\n",
    "    n = random.randint(1, counter.total)\n",
    "    cumulative = 0\n",
    "    for ch in counter:\n",
    "        cumulative += counter[ch]\n",
    "        if cumulative >= n: \n",
    "            return ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Shakespeare from different order models\n",
    "\n",
    "Let's try to generate text based on different language-model orders. Let's start with something silly:\n",
    "\n",
    "## order 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fireve notenink by in and my hillan foll harseceare.\n",
      "\n",
      "Secers faing tom th, dre met speat's ano weauld derve,\n",
      "OPHOPANG Roy, so grive us thishat me hall\n",
      "That liall hen a\n",
      "goin souren;' ther hou hust peavio.\n",
      "BET:\n",
      "Forat th ofend now bainch sed cur hou mat fatied shour men of\n",
      "And ne hinese so may; somminto scall for taking iftlee the been siome this and naby thure dont.\n",
      "RO:\n",
      "Ther to-ny no ithe of I me drit, car! wer talk army deris to not ity\n",
      "shearmonerstlet he gove proultre dink agiver cand swe ithe a glus,\n",
      "SIDUKENE:\n",
      "Yor.\n",
      "\n",
      "Marrows anters, stemusere, bourects smennown here me thave ap asleand my forter tel\n",
      "So liket wit.\n",
      "\n",
      "Runt?\n",
      "\n",
      "Nor me for pose\n",
      "Def ing thempood I coame thoppestimp.\n",
      "Tell ittle willy\n",
      "As con\n",
      "To thy soner\n",
      "bless'd hasarcults what of thers nour\n",
      "Why laillord!\n",
      "\n",
      "MIL:\n",
      "Forent itill down, ficke ord younsucks, lie dook:\n",
      "Hear, a dill sty 't of togue; the I daus swast con now's anch lown re.\n",
      "MENRY VIRANTO:\n",
      "The ty, gonfectis me,\n",
      "Tak Ridst\n",
      "But all the of thothienday wilead him.\n",
      "\n",
      "By to yess war\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=2)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## order 4 \n",
    "\n",
    "Order 2 was not so great... but what if we increase the order to 4?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Servantagem mayst can shall tends, the been of whether that senses of thou not her, sure that sure remain, thronet an expense.\n",
      "\n",
      "Fool, her?\n",
      "'Twas be told me?\n",
      "\n",
      "SHALLOW:\n",
      "De siege.\n",
      "\n",
      "VALENTIO:\n",
      "Never thy Montentend of rever my good quited, with laid best be? Tellingerous beseech were month.\n",
      "\n",
      "KING CLAUDIUS:\n",
      "He is faces.\n",
      "\n",
      "CLAUDIUS:\n",
      "In sure, and I hit foolish\n",
      "As well teach yours, Here,\n",
      "How does into thing more upon moves mother funerald it my very thank\n",
      "That here often'd me.\n",
      "Her hath broth\n",
      "What wingeneral rob: if them here is jestion the baby you and thee.\n",
      "\n",
      "HELENA:\n",
      "O, their is,\n",
      "And fig orders of fixed in these edges I would up, you this, for the good Service wilt seems to Caesar sing, smoking; and die, you may come wish these bed.\n",
      "\n",
      "PETRUCHIO:\n",
      "Falstaff ore to fast would I have show naked not what let us wrathe, and promio, thouse: and Mortime:\n",
      "Both about of his that's hence how dukes inder you.\n",
      "\n",
      "TRANIO:\n",
      "At Melun.\n",
      "\n",
      "Fourtier and take my some frust and my known\n",
      "Ever her too.\n",
      "\n",
      "TALBOT:\n",
      "La man h\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## order 7\n",
    "\n",
    "Order 4 is already quite reasonable, and reads like English. Just 4 letters history! What if we increase it to 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Soft! take my castle call a new-devised impeach young one,\n",
      "Were not\n",
      "worth ten time to speak out,\n",
      "Which Salique land:\n",
      "Your mark his charge and sack great earnest of his practise, Gloucester, thou mean, he's hunted with this here stands,\n",
      "'Tis one with such a question: his disturbed spirit, set a-work;\n",
      "And so should I have in the liveries, all encertain money.\n",
      "\n",
      "PERICLES:\n",
      "How can these our favours\n",
      "Have sat too curious, three thou wert as wise and right royal 'twas mine;\n",
      "It is some taste of hers,\n",
      "Hath seen such a place the event.\n",
      "'Tis politic; he crosses to it, boy.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Give him,\n",
      "for my battle's lost:\n",
      "That well;\n",
      "But bear my life.\n",
      "I beg thy particular,--you had known well I shaked,\n",
      "Which I feel.\n",
      "I fight a question. Hubert, keep aloof at bay:\n",
      "Sell ever soft hours,\n",
      "Unless than thine own gladness he passage 'tis!--whose eyes can volley.\n",
      "\n",
      "HAMLET:\n",
      "How angerly.\n",
      "\n",
      "PETRUCHIO:\n",
      "Why, then it is\n",
      "There were in our loves you,\n",
      "A sea of glory, Gallia wars.\n",
      "\n",
      "BASTARD:\n",
      "Though he be n\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=7)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about order 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Doth this news; yet what I have been a breakfast, washes his\n",
      "hands, and save yourself!\n",
      "My master, my dear Moth?\n",
      "\n",
      "MOTH:\n",
      "No, nor a man cannot make\n",
      "him eat it that spake\n",
      "that word?\n",
      "\n",
      "QUINTUS:\n",
      "Not so, an't please your highness, give us any thing for my labour by his own attaint?\n",
      "'Tis doubt he will utter?\n",
      "\n",
      "BRUTUS:\n",
      "Hence! I will follow it! Come, and get to Naples? Keep in Tunis,\n",
      "And Ferdinand, her brothers both from death,\n",
      "But lusty, young, and of antiquity too; bawd-born.\n",
      "Farewell, sweet Jack\n",
      "Falstaff, where hath been prophesied France and Ireland\n",
      "Bear that play;\n",
      "For never yet a breaker of\n",
      "proverbs: he will answer it. Some pigeons, Davy, a couple of Ford's\n",
      "knaves, his hinds, bars me the poor\n",
      "duke's office should do the duke of this place and great\n",
      "ones I dare not: Sir Pierce of Exton, who\n",
      "lately came from valiant Oxford?\n",
      "How far hence\n",
      "In mine own away;\n",
      "But you gave in charge,\n",
      "Is now dishonour me.\n",
      "\n",
      "SUFFOLK:\n",
      "Who waits there?\n",
      "\n",
      "RODERIGO:\n",
      "I know not; except, in that as ever\n",
      "knapped\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=10)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This works pretty well\n",
    "\n",
    "With an order of 4, we already get quite reasonable results. Increasing the order to 7 (about a word and a half of history) or 10 (about two short words of history) already gets us quite passable Shakepearan text. I'd say it is on par with the examples in Andrej's post. And how simple and un-mystical the model is!\n",
    "\n",
    "## Aside: First words\n",
    "\n",
    "One thing you may have noticed: all the generated passages start with \"Fi\". Why is that? Because the training data starts with the word \"First\" (preceeded by padding), and so when we go to randomly `generate_text`, the only thing that follows the initial padding is the word \"First\". We could get more variety in the generated text by breaking the training text up into sections  and inserting padding at the start of each section. But that would require some knowledge of the structure of the training text; right know the only assumption is that it is a sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n"
     ]
    }
   ],
   "source": [
    "! head shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So why am I impressed with the RNNs after all?\n",
    "\n",
    "Generating English a character at a time -- not so impressive in my view. The RNN needs to learn the previous *n* letters, for a rather small *n*, and that's it. \n",
    "\n",
    "However, Karpathy's C++ code generation example is very impressive. Why? because of the context awareness. Note that in all of Karpathy's posted examples, the code is well indented, the braces and brackets are correctly nested, and even the comments start and end correctly. This is not something that can be achieved by simply looking at the previous *n* characters. \n",
    "\n",
    "If Karpathy's examples are not cherry-picked, and the output is generally that nice, then the LSTM did learn something not trivial at all.\n",
    "\n",
    "# Linux Kernel C++ Code\n",
    "\n",
    "Just for the fun of it, let's see what our simple language model does with the Linux-kernel code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  241465  759639 6206997 linux_input.txt\n"
     ]
    }
   ],
   "source": [
    "! [ -f linux_input.txt ] || curl -O https://norvig.com/ngrams/linux_input.txt\n",
    "! wc linux_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel_stat.h>\n",
      "\n",
      "int rcu_cpu_notify(CPU_CLUSTER_PM_EXIT, -1, NULL);\n",
      "}\n",
      "\n",
      "bool __weak is_swbp_insn\n",
      " * Returns:\n",
      " *\tZero for success, 0 (invalid alignment with below mechanisms in the kprobe gone and remove\n",
      " * @action: action to SIG_DFL for a signal frame,\n",
      "\t   and will be woken\n",
      " * up from TASK_TRACED);\n",
      "\tif (mod->state == MODULE_STATE_GOING:\n",
      "\t\tstate = possible;\n",
      "\t\t\tbreak;\n",
      "\t\t\trest++;\n",
      "\t\t}\n",
      "\t\t/*\n",
      "\t\t * Another cpu said 'go' */\n",
      "\t\t/* Still using kdb, this problematic.\n",
      " */\n",
      "void init_sched_dl_class(void)\n",
      "{\n",
      "\tfield_cachep = KMEM_CACHE(vm_area_struct *vma, struct autogroup *autogroup_kref_put(ag);\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "void do_raw_write_can_lock(l)\twrite_can_lock(l)\n",
      "\n",
      "/*\n",
      " * Software Foundation, and allows traversing */\n",
      "static int perf_output_sample_rate __read_mostly futex_hash_bucket(futex));\n",
      " *     smp_mb() anyway for documentation of its parent\n",
      "\t * using getname.\n",
      " *\n",
      " * default: 5 msec, units: microseconds, all such timers will fire\n",
      " * at the end of this function implementation\n",
      " * @num: number of tot\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=10)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/handle.c\n",
      " *\n",
      " * Copyright (C) 2012 Dario Faggioli <raistlin@linux.it>,\n",
      " *                  |         |\\n\");\n",
      "}\n",
      "\n",
      "static int __read_mostly =\n",
      "{\n",
      "\t.name\t\t= \"irqsoff\",\n",
      "\t.init\t\t= preemptoff_tracer __read_mostly sysctl_hung_task_timeout_secs(struct ctl_table *table,\n",
      "\t\t  int write, void *data),\n",
      "\t\t struct lock_list *unsafe_entry,\n",
      "\t\t\tstruct lock_class_key irq_desc_lock_class;\n",
      "\n",
      "#if defined(CONFIG_RCU_TRACE */\n",
      "\n",
      "static __init int user_namespace *ns = task_active_pid_ns(parent));\n",
      "\tinfo.si_uid = from_kuid_munged(current_user_ns(), task_uid(p));\n",
      "\tstruct siginfo info;\n",
      "\n",
      "\tif (argc != 1)\n",
      "\t\treturn -EINVAL;\n",
      "\t}\n",
      "#endif\n",
      "\n",
      "#ifdef CONFIG_SMP\n",
      "\n",
      "static void\n",
      "irq_thread_check_affinity(struct rcu_node *rnp)\n",
      "{\n",
      "\treturn rnp->gp_tasks != NULL;\n",
      "}\n",
      "\n",
      "/*\n",
      " * return non-zero if there is a SIGKILL that should be deferred, ETT_NONE if nothing to defer.\n",
      " */\n",
      "enum event_trigger_free() (see\n",
      " *\ttrace_event_trigger_enable_disable(file, 0);\n",
      "\t\t\tbreak;\n",
      "\t\t}\n",
      "\n",
      "\t\t/*\n",
      "\t\t * Wait for all preempt-disabled section so we can as wel\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=15)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/itimer.c\n",
      " *\n",
      " * Copyright (C) 2008 Red Hat, Inc., Peter Zijlstra <pzijlstr@redhat.com>\n",
      " *  Copyright (C) 2004, 2005, 2006 Red Hat, Inc., Ingo Molnar <mingo@redhat.com>\n",
      " *  Copyright (C) 2004 IBM Corporation\n",
      " *\n",
      " *  Author: Serge Hallyn <serue@us.ibm.com>\n",
      " *\n",
      " *  This program is distributed in the hope that it will be useful,\n",
      " * but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      " * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      " * GNU General Public License as\n",
      " *  published by the Free Software Foundation; version 2\n",
      " * of the License, or (at\n",
      " * your option) any later version.\n",
      " *\n",
      " * This program is free software; you can redistribute it and/or\n",
      " * modify it under the terms of the GNU GPL, version 2\n",
      " *\n",
      " * This file implements counting semaphores.\n",
      " * A counting semaphore may be acquired 'n' times before sleeping.\n",
      " * See mutex.c for single-acquisition sleeping locks which enforce\n",
      " * rules which allow code to be debugged more easily.\n",
      " */\n",
      "\n",
      "/*\n",
      " * Some \n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=20)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/manage.c\n",
      " *\n",
      " * Copyright (C) 2008-2014 Mathieu Desnoyers\n",
      " *\n",
      " * This program is distributed in the hope that it will be useful, but\n",
      " * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n",
      " * FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      " * GNU General Public Licence\n",
      " * as published by the Free Software Foundation, version 2 of the\n",
      " *  License.\n",
      " *\n",
      " *  Jun 2006 - namespaces support\n",
      " *             OpenVZ, SWsoft Inc.\n",
      " *    (C) 2007 Sukadev Bhattiprolu <sukadev@us.ibm.com>, IBM\n",
      " *     Many thanks to Oleg Nesterov for comments and help\n",
      " *\n",
      " */\n",
      "\n",
      "#include <linux/irq_work.h>\n",
      "#include <linux/syscalls.h>\n",
      "#include <linux/swapops.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/module.h>\n",
      "#include <linux/kmod.h>\n",
      "#include <linux/sched.h>\t/* for cond_resched */\n",
      "#include <linux/types.h>\n",
      "#include <linux/mutex.h>\n",
      "#include <linux/proc_fs.h>\n",
      "#include <linux/memory.h>\n",
      "#include <linux/task_io_accounting_ops.h>\n",
      "#include <linux/proc_fs.h>\n",
      "#include <linux/highmem.h>\n",
      "#includ\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/manage.c\n",
      " *\n",
      " * Copyright (C) 2010 Red Hat, Inc.\n",
      " *\n",
      " * Note: Most of this code is borrowed heavily from the original softlockup\n",
      " * detector, so thanks to Ingo for the initial implementation (includes suggestions from\n",
      " *\t\tRusty Russell).\n",
      " * 2004-Aug\tUpdated by Prasanna S Panchamukhi <prasanna@in.ibm.com> Changed Kprobes\n",
      " *\t\texceptions notifier as suggested by Andi Kleen.\n",
      " * 2004-July\tSuparna Bhattacharya <suparna@in.ibm.com> added jumper probes\n",
      " *\t\tinterface to access function arguments.\n",
      " * 2004-Sep\tPrasanna S Panchamukhi\n",
      " *\t\t<prasanna@in.ibm.com> with\n",
      " *\t\thlists and exceptions notifier to be first on the priority list.\n",
      " * 2005-May\tHien Nguyen <hien@us.ibm.com>, Jim Keniston\n",
      " *\t\t<jkenisto@us.ibm.com> and Prasanna S Panchamukhi <prasanna@in.ibm.com> Changed Kprobes\n",
      " *\t\texceptions notifier as suggested by Andi Kleen.\n",
      " * 2004-July\tSuparna Bhattacharya <suparna@in.ibm.com> added function-return probe instances associated with the event\n",
      " *\n",
      " * If an event has triggers and any of those triggers has a filter or\n",
      " * a post_trigger, trigger invocation is split\n",
      " *\tin two - the first part checks the filter using the current\n",
      " *\ttrace record; if a command has the @post_trigger flag set, it\n",
      " *\tsets a bit for itself in the return value, otherwise it\n",
      " *\tdirectly invokes the trigger.  Once all commands have been\n",
      " *\teither invoked or set their return flag, the current record function, skip it.\n",
      " * If the ops ignores the function via notrace filter, skip it.\n",
      " */\n",
      "static inline void\n",
      "__sched_info_switch(struct rq *rq, struct task_struct *p;\n",
      "\tint retval;\n",
      "\n",
      "\tif (!desc || !irqd_can_balance(&desc->irq_data)) {\n",
      "\t\t/*\n",
      "\t\t * Already running: If it is shared get the other\n",
      "\t\t * CPU to go looking for our mystery interrupt too\n",
      "\t\t */\n",
      "\t\tdesc->istate |= IRQS_SUSPENDED;\n",
      "\t__disable_irq(desc, irq);\n",
      "out:\n",
      "\tirq_put_desc_busunlock(desc, flags);\n",
      "\treturn err;\n",
      "}\n",
      "/*\n",
      " * RT-Mutexes: blocking mutual exclusion locks with PI support\n",
      " *\n",
      " * started by Ingo Molnar and Thomas Gleixner:\n",
      " *\n",
      " *  Copyright (C) 1991, 1992  Linus Torvalds\n",
      " *\n",
      " * Modified to make sys_syslog() more flexible: added commands to\n",
      " * return the last 4k of kernel messages, regardless of whether\n",
      " * they've been read or not.  Added option to suppress kernel printk's\n",
      " * to the console.  Added hook for sending the console messages\n",
      " * elsewhere, in preparation for detecting the next grace period.\n",
      "\t * But we can only be sure that RCU is idle if we are looking\n",
      "\t * at the root rcu_node structure's lock in order to\n",
      "\t * start one (if needed).\n",
      "\t */\n",
      "\tif (rnp != rnp_root) {\n",
      "\t\traw_spin_lock(&ctx->lock);\n",
      "}\n",
      "\n",
      "static inline void debug_init(struct timer_list *timer, void (*fn)(unsigned long),\n",
      "\t\t\t\ti == entry->nb_args - 1 ? \"\" : \", \");\n",
      "\t}\n",
      "\tpos += snprintf(buf + pos, LEN_OR_ZERO, \" %s=%s\",\n",
      "\t\t\t\ttp->args[i].name);\n",
      "\t}\n",
      "\n",
      "#undef LEN_OR_ZERO\n",
      "\n",
      "\t/* return the length of the given event. Will return\n",
      " * the length of the time extend if the event is a\n",
      " * time extend.\n",
      " */\n",
      "static inline void register_handler_proc(irq, new);\n",
      "\tfree_cpumask_var(mask);\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "#ifdef CONFIG_COMPAT\n",
      "static long posix_cpu_nsleep_restart(struct restart_block *restart)\n",
      "{\n",
      "\tenum  alarmtimer_type type,\n",
      "\t\t\tstruct pid *new)\n",
      "{\n",
      "\tstruct pid_link *links)\n",
      "{\n",
      "\tenum pid_type type;\n",
      "\n",
      "\tfor (type = PIDTYPE_PID; type < PIDTYPE_MAX; ++type) {\n",
      "\t\tINIT_HLIST_NODE(&ri->hlist);\n",
      "\t\tkretprobe_table_unlock(hash, &flags);\n",
      "\t\thlist_add_head(&inst->hlist, &rp->free_instances);\n",
      "\t}\n",
      "\n",
      "\trp->nmissed = 0;\n",
      "\t/* Establish function entry probe to avoid possible hanging */\n",
      "static int trace_test_buffer_cpu(buf, cpu);\n",
      "\t\tif (ret)\n",
      "\t\t\tbreak;\n",
      "\t}\n",
      "\n",
      "\t/*\n",
      "\t * We can't hold ctx->lock when iterating the ->flexible_group list due\n",
      "\t * to allocations, but we need to prevent that we loop forever in the hrtimer\n",
      "\t * interrupt routine. We give it 3 attempts to avoid\n",
      "\t * overreacting on some spurious event.\n",
      "\t *\n",
      "\t * Acquire base lock for updating the offsets and retrieving\n",
      "\t * the current rq->clock timestamp, except that would require using\n",
      "\t * atomic ops.\n",
      "\t */\n",
      "\tif (irq_delta > delta)\n",
      "\t\tirq_delta = delta;\n",
      "\n",
      "\trq->prev_irq_time += irq_delta;\n",
      "\tdelta -= irq_delta;\n",
      "#endif\n",
      "#ifdef CONFIG_NO_HZ_FULL\n",
      "static void nohz_kick_work_fn(struct work_struct *work)\n",
      "{\n",
      "\tsmp_wmb();\t/* see set_work_pool_and_clear_pending(work, pool->id);\n",
      "\n",
      "\t\tspin_unlock(&pool->lock);\n",
      "\t/* see the comment above the definition of WQ_POWER_EFFICIENT */\n",
      "#ifdef CONFIG_WQ_POWER_EFFICIENT_DEFAULT\n",
      "static bool wq_power_efficient;\n",
      "#endif\n",
      "\n",
      "module_param_named(cmd_enable, kdb_cmd_enabled, int, 0600);\n",
      "\n",
      "char kdb_grep_string[];\n",
      "#define KDB_GREP_STRLEN 256\n",
      "extern int kdb_grep_trailing;\n",
      "extern char *kdb_cmds[];\n",
      "extern unsigned int max_bfs_queue_depth;\n",
      "\n",
      "static unsigned int relay_file_poll(struct file *file, const char __user *ubuf,\n",
      "\t\t  size_t cnt, loff_t *ppos)\n",
      "{\n",
      "\treturn -ENOSYS;\n",
      "}\n",
      "\n",
      "int proc_dointvec_jiffies,\n",
      "\t},\n",
      "\t{\n",
      "\t\t.procname\t= \"sched_cfs_bandwidth_slice(void)\n",
      "{\n",
      "\treturn ((trace_type & TRACER_IRQS_OFF) &&\n",
      "\t\tirqs_disabled());\n",
      "}\n",
      "#else\n",
      "# define perf_compat_ioctl NULL\n",
      "#endif\n",
      "\n",
      "int perf_event_task_disable(void)\n",
      "{\n",
      "\tstruct trace_buffer\ttrace_buffer;\n",
      "#ifdef CONFIG_TR\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm, length=5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Order 10 is pretty much junk. In order 15 things sort-of make sense, but we jump abruptly between the `[sic]`\n",
    "and by order 20 we are doing quite nicely â€” but are far from keeping good indentation and brackets. \n",
    "\n",
    "How could we? we do not have the memory, and these things are not modeled at all. While we could quite easily enrich our model to support also keeping track of brackets and indentation (by adding information such as \"have I seen ( but not )\" to the conditioning history), this requires extra work, non-trivial human reasoning, and will make the model significantly more complex. \n",
    "\n",
    "Karpathy's LSTM, on the other hand, seemed to have just learn it on its own. And that's impressive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
