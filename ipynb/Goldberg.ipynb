{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Unreasonable Effectiveness of Character-level Language Models\n",
    "# (and why RNNs are still cool)\n",
    "\n",
    "## By [Yoav Goldberg](http://www.cs.biu.ac.il/~yogo) (2015)\n",
    "\n",
    "#### (with minor changes by Peter Norvig (2022) for modern Python 3)\n",
    "\n",
    "<hr>\n",
    "\n",
    "[RNNs](https://en.wikipedia.org/wiki/Recurrent_neural_network), [LSTMs](https://en.wikipedia.org/wiki/Long_short-term_memory) and [Deep Learning](https://en.wikipedia.org/wiki/Deep_learning) are all the rage, and a recent [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy is doing a great job explaining what these models are and how to train them.\n",
    "It also provides some very impressive results of what they are capable of.  This is a great post, and if you are interested in natural language, machine learning or neural networks you should definitely read it. \n",
    "\n",
    "Go [**read it now**](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), then come back here. \n",
    "\n",
    "You're back? Good. Impressive stuff, huh? How could the network learn to imitate the input like that?\n",
    "Indeed. I was quite impressed as well.\n",
    "\n",
    "However, it feels to me that most readers of the post are impressed by the wrong reasons.\n",
    "This is because they are not familiar with **unsmoothed maximum-liklihood character level language models** and their unreasonable effectiveness at generating rather convincing natural language outputs.\n",
    "\n",
    "In what follows I will briefly describe these character-level maximum-likelihood langauge models, which are much less magical than RNNs and LSTMs, and show that they too can produce a rather convincing Shakespearean prose. I will also show about 30 lines of python code that take care of both training the model and generating the output. Compared to this baseline, the RNNs may seem somehwat less impressive. So why was I impressed? I will explain this too, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsmoothed Maximum Likelihood Character Level Language Model \n",
    "\n",
    "The name is quite long, but the idea is very simple.  We want a model whose job is to guess the next character based on the previous *n* characters. For example, having seen `ello`, the next characer is likely to be either a commma or space (if we assume is is the end of the word \"hello\"), or the letter `w` if we believe we are in the middle of the word \"mellow\" or \"yellow\". Humans are quite good at this, but of course seeing a larger history makes things easier (if we were to see 5 letters instead of 4, the choice between space and `w` would have been much easier).\n",
    "\n",
    "We will call *n*, the number of letters we need to guess based on, the _order_ of the language model.\n",
    "\n",
    "RNNs and LSTMs can potentially learn infinite-order language model (they guess the next character based on a \"state\" which supposedly encodes all the previous history). We here will restrict ourselves to a fixed-order language model.\n",
    "\n",
    "So, we are seeing *n* letters, and need to guess the *n+1*th one. We are also given a large-ish amount of text (say, all of Shakespeare's works) that we can use. How would we go about solving this task?\n",
    "\n",
    "Mathematically, we would like to learn a function *P(c* | *h)*. Here, *c* is a character, *h* is a *n*-character history, and *P(c* | *h)* stands for how likely is it to see *c* after we've seen *h*.\n",
    "\n",
    "Perhaps the simplest approach would be to just count and divide (a.k.a **maximum likelihood estimates**). We will count the number of times each letter *c* appeared after *h*, and divide by the total numbers of letters appearing after *h*. The **unsmoothed** part means that if we did not see a given letter following *h*, we will just give it a probability of zero.\n",
    "\n",
    "And that's all there is to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code\n",
    "\n",
    "Here is the code for training a language model, which implements *P(c* | *h)* with a counter of the number of times we have seen each character, for each history. The function `train_char_lm` takes a filename  to read the characters from. `order` is the history size to consult. Note that we pad the data with `order` leading characters so that we also learn how to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(collections.defaultdict):\n",
    "    \"\"\"A mapping from `order` history characters to possible next characters and their \n",
    "    frequency, e.g. {'spea': Counter({'k': 9, 'r': 1})} lets us generate 'speak' or 'spear'.\"\"\"\n",
    "    def __init__(self, order): \n",
    "        self.order = order\n",
    "        self.default_factory = collections.Counter \n",
    "\n",
    "def train_char_lm(fname, order=4) -> LanguageModel:\n",
    "    \"\"\"Train an character-level language model of given order on all the text in `fname`.\"\"\"\n",
    "    lm = LanguageModel(order)\n",
    "    data = (order * PAD) + open(fname).read()\n",
    "    for i in range(order, len(data)):\n",
    "        history, char = data[i - order:i], data[i]\n",
    "        lm[history][char] += 1\n",
    "    for counter in lm.values():\n",
    "        counter.total = sum(counter.values()) # Cache total counts (for sample_character)\n",
    "    return lm\n",
    "\n",
    "PAD = '`' # Character to pad the beginning of a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a model on Andrej's Shakespeare text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  167204  832301 4573338 shakespeare_input.txt\n"
     ]
    }
   ],
   "source": [
    "! [ -f shakespeare_input.txt ] || curl -O https://norvig.com/ngrams/shakespeare_input.txt\n",
    "! wc shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Now let's do some queries on the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'r': 35,\n",
       "         'w': 480,\n",
       "         'u': 22,\n",
       "         ',': 16,\n",
       "         ' ': 8,\n",
       "         '.': 4,\n",
       "         '?': 4,\n",
       "         ':': 3,\n",
       "         'n': 1,\n",
       "         \"'\": 10,\n",
       "         '!': 4})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['ello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'t': 864})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['Firs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'C': 119,\n",
       "         'f': 14,\n",
       "         'i': 21,\n",
       "         't': 67,\n",
       "         'u': 2,\n",
       "         'S': 203,\n",
       "         'h': 24,\n",
       "         's': 41,\n",
       "         'R': 1,\n",
       "         'b': 31,\n",
       "         'c': 16,\n",
       "         'O': 23,\n",
       "         'w': 30,\n",
       "         'a': 28,\n",
       "         'm': 28,\n",
       "         'n': 25,\n",
       "         'I': 12,\n",
       "         'L': 133,\n",
       "         'M': 74,\n",
       "         'l': 13,\n",
       "         'o': 38,\n",
       "         'H': 5,\n",
       "         'd': 19,\n",
       "         'W': 42,\n",
       "         'K': 10,\n",
       "         'q': 2,\n",
       "         'G': 112,\n",
       "         'g': 14,\n",
       "         'k': 5,\n",
       "         'e': 4,\n",
       "         'y': 3,\n",
       "         'r': 9,\n",
       "         'p': 11,\n",
       "         'A': 7,\n",
       "         'P': 18,\n",
       "         'F': 15,\n",
       "         'v': 3,\n",
       "         'T': 4,\n",
       "         'D': 4,\n",
       "         'B': 12,\n",
       "         'N': 1,\n",
       "         \"'\": 1,\n",
       "         'E': 2})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['rst ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `\"ello\"` is followed by either space, punctuation or `w` (or `r`, `u`, `n`), `\"Firs\"` is pretty much deterministic, and the word following `\"rst \"` can start with pretty much every letter. \n",
    "\n",
    "## Character Probabilities\n",
    "\n",
    "We can extract probabilities *P(c* | *h)* from the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(c, h, lm) -> float: \n",
    "    \"\"\"The probability P(c | h) of next character c given history h, according to the language model.\"\"\"\n",
    "    return lm[h][c] / lm[h].total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817717206132879"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P('w', 'ello', lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P('t', 'Firs', lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P('x', 'Firs', lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16292134831460675"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P('S', 'rst ', lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating sample text from a model\n",
    "\n",
    "To randomly generate a sample text from a model, we maintain a history of *order* characters, starting  with all pad characters. We then enter a loop that looks up the history in the language model, randomly samples a character from the history's counter, then updates the history by dropping its first character and adding the randomly-sampled character to the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lm, length=1000) -> str:\n",
    "    \"\"\"Sample a random `length`-long passage from `lm`.\"\"\"\n",
    "    history = lm.order * PAD\n",
    "    text = []\n",
    "    for _ in range(length):\n",
    "        c = sample_character(lm[history])\n",
    "        history = history[1:] + c\n",
    "        text.append(c)\n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample a single character *c* from a counter, randomly choose an integer *n* from 1 to the total count of characters in the counter, then iterate through the counter until the cumulative total of the counts meets or exceeds *n*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_character(counter) -> str:\n",
    "    \"\"\"Randomly sample the nth character from the counter.\"\"\"\n",
    "    n = random.randint(1, counter.total)\n",
    "    cumulative = 0\n",
    "    for c in counter:\n",
    "        cumulative += counter[c]\n",
    "        if cumulative >= n: \n",
    "            return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Shakespeare text from different order models\n",
    "\n",
    "Let's try to generate text based on different language-model orders. Let's start with something silly:\n",
    "\n",
    "## Order 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fir,\n",
      "ACBENE:\n",
      "But st thaverforn'd his then my ther's one,\n",
      "Whe Lonce de kinger, ap the sa? Whee mus ne.\n",
      "\n",
      "But of ithice soaciven loven one my I ch hight sithe or ble-ern the my wherephy graidia,\n",
      "a belf;\n",
      "Ay, quare hins an an:\n",
      "Whem'd cur beek, Hecomat on my he arry Riciuse, giver nothery: nal.\n",
      "\n",
      "DUKE:\n",
      "Hold but,\n",
      "And to moul ford\n",
      "ant ace\n",
      "wore hime re shathis onsol th I dis spried!\n",
      "\n",
      "SIR Lorthat mor ent: sur suchast the spoo, wit, the in hief-wis hand lor reand way be wo set this solorsee Dand, loot the makin am hisfourab:\n",
      "Bar his the frortithe uponowee:\n",
      "Is han hour leyessin on to and take my pas and to alset hatterialow\n",
      "Suchaso you\n",
      "be creest to tak alks.\n",
      "\n",
      "PATIANTIS Fraff,\n",
      "ime proier theatholk yould a the raingrain anith, th hardso I halmorge th wall wast liver,\n",
      "in theall-dayst this craire swot Pere whow And nobeece\n",
      "Tithall, ar,\n",
      "Thar und of ch mandrefor the\n",
      "Andes, Dest allighe an:\n",
      "Warrow thavererstund no lad your som of why nothat my whows be pur hat chou!\n",
      "\n",
      "SLYCUS:\n",
      "It th withith it pon spe myse \n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=2)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order 4 \n",
    "\n",
    "Order 2 was not so great... but what if we increase the order to 4?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Murderer:\n",
      "Unquet thee one; and chant:\n",
      "Birons--\n",
      "Poor cheeks they much my bosom sorrow! how stops as him your honest,\n",
      "And it better? Rugby, if you pleasures, all me writter of men.\n",
      "\n",
      "EGLAMOUR:\n",
      "Ay, but him a tready the work madam?\n",
      "\n",
      "MENENIUS:\n",
      "Lamentony conquer'd in purpose; above.\n",
      "\n",
      "SIR ANDRONICUS:\n",
      "And be my pardon my father for ink, he's greaten him bound thus?\n",
      "Let thee,\n",
      "And lady, willius' tongue deed world.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "As love hold, to be constantiately captains o' thee, purs and Petructified: but his judgment.\n",
      "\n",
      "THUR:\n",
      "O Lord of thou the bold not as well take thus sends--takings thready friends, but that he sleep o' the neverended.\n",
      "\n",
      "MACDUFF:\n",
      "Venice that blasp and him was faults struth the more of men so well;\n",
      "Ford, I should betray in this in the bear you,\n",
      "To sand I hadst travery,\n",
      "Yet, herrily;\n",
      "And bed to king: God sense\n",
      "Caius with and still behind.\n",
      "\n",
      "SUFFOLK:\n",
      "Right a tear\n",
      "shout of suborned so prince him. Your titless'd the better is be the she, swell!\n",
      "This a little come, and sons;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Order 7\n",
    "\n",
    "Order 4 is already quite reasonable, and reads like English. Just 4 letters history! What if we increase it to 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before I keep the\n",
      "sounder a rhyme nor pinch the engenders you:\n",
      "And he was the valour that blows, they did;\n",
      "So I grow; I prospero my lords,\n",
      "Will creep into strong,\n",
      "And I'll rake up, pipers.\n",
      "\n",
      "FALSTAFF:\n",
      "Fie! you played the midwife present a large and grave,\n",
      "Being simply; the honour,\n",
      "Purchase the good hope\n",
      "The period to make us medicine of kindness: I dare not making?\n",
      "\n",
      "GONZALO:\n",
      "All's hush'd with the vast sea: at land:\n",
      "Come, come, come, though, haply, are you colours turn'd youth: who best king of though\n",
      "The enmity.\n",
      "\n",
      "ORLEANS:\n",
      "He's alive, I was not angry indeed to him.\n",
      "\n",
      "MENENIUS:\n",
      "I loved withal: except a sword, despite of brooded waters, and\n",
      "that all tire.\n",
      "\n",
      "WARWICK:\n",
      "Ay, sir, an she to be doubtful for those that\n",
      "it will have my country's wreck, to transportance;\n",
      "Sometimes, like a rebel,\n",
      "And dreadful object him, till the fashion? do I not known\n",
      "No less home, you wrestler's\n",
      "heels a huge to be impart to hide thee much to live created one of you; which marriage move\n",
      "And she is fast\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=7)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about order 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Read the will.\n",
      "\n",
      "ANTONY:\n",
      "He will seek\n",
      "Some way to leave as keep; whose top to climb\n",
      "Is certain and shameless callet know herself.\n",
      "Helen of Greece! what should I curse the ducats.'\n",
      "\n",
      "SALARINO:\n",
      "That's not my meaning:\n",
      "go to thy cost.\n",
      "\n",
      "VERNON:\n",
      "There is no force in the first, how get hence:\n",
      "Why should the gods to witness from their colour fly,\n",
      "And to become the function takes,\n",
      "The ear more quick of apprehensions, motions,\n",
      "as promising\n",
      "Than a wild dedication; facere, as it grows.\n",
      "\n",
      "Poet:\n",
      "Ay, that I can do it: I\n",
      "commend you well, my lord,\n",
      "Grievous complaint; hasty and tinder-like\n",
      "upon too trivial motion; one that, in King Edward's good success hath done to-day\n",
      "Mad and fantastical banquet, just so much they love his lady was but devised at first, to try her skill,\n",
      "Reignier, whose frank heart gave all,--\n",
      "O, that way and you to your majesty had call'd you up, have held him dear.\n",
      "\n",
      "BEVIS:\n",
      "Come, and believe thee,\n",
      "Were they not by you?\n",
      "\n",
      "LENNOX:\n",
      "Ay, my good lord;\n",
      "'Tis but the gods to inte\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=10)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This works pretty well\n",
    "\n",
    "With an order of 4, we already get quite reasonable results. Increasing the order to 7 (about a word and a half of history) or 10 (about two short words of history) already gets us quite passable Shakepearan text. I'd say it is on par with the examples in Andrej's post. And how simple and un-mystical the model is!\n",
    "\n",
    "## Aside: First words\n",
    "\n",
    "One thing you may have noticed: all the generated passages start with \"Fi\". Why is that? Because the training data starts with the word \"First\" (preceeded by padding), and so when we go to randomly `generate_text`, the only thing that follows the initial padding is the word \"First\". We could get more variety in the generated text by breaking the training text up into sections  and inserting padding at the start of each section. But that would require some knowledge of the structure of the training text; right know the only assumption is that it is a sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n"
     ]
    }
   ],
   "source": [
    "! head shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So why am I impressed with the RNNs after all?\n",
    "\n",
    "Generating English a character at a time -- not so impressive in my view. The RNN needs to learn the previous *n* letters, for a rather small *n*, and that's it. \n",
    "\n",
    "However, Karpathy's C++ code generation example is very impressive. Why? because of the context awareness. Note that in all of Karpathy's posted examples, the code is well indented, the braces and brackets are correctly nested, and even the comments start and end correctly. This is not something that can be achieved by simply looking at the previous *n* characters. \n",
    "\n",
    "If Karpathy's examples are not cherry-picked, and the output is generally that nice, then the LSTM did learn something not trivial at all.\n",
    "\n",
    "# Linux Kernel C++ Code\n",
    "\n",
    "Just for the fun of it, let's see what our simple language model does with the Linux-kernel code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  241465  759639 6206997 linux_input.txt\n"
     ]
    }
   ],
   "source": [
    "! [ -f linux_input.txt ] || curl -O https://norvig.com/ngrams/linux_input.txt\n",
    "! wc linux_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel.h>\n",
      "#include <linux/module.h>\n",
      "#include <linux/proc_fs.h>\n",
      "#include <linux/sched/rt.h>\n",
      "#include \"rcu.h\"\n",
      "\n",
      "MODULE_AUTHOR(\"Paul E. McKenney <paulmck@us.ibm.com), IBM Corp. 2006\n",
      " *       - If the kernel\n",
      " * interface for test commands. */\n",
      "static int set_tracing_thresh > GRAPH_MAX_FUNC_TEST) {\n",
      "\t\ttrace_array_put(this_tr);\n",
      "\tmutex_unlock_pi;\n",
      "\n",
      "\t/*\n",
      "\t * One idle CPUs. */\n",
      "\tshuffle_intervals\n",
      "\t * (think \"ticks\") worth of data\n",
      " */\n",
      "static int func_id)\n",
      "{\n",
      "\tswitch (ret) {\n",
      "\t\t\tif (group_rq && (rt_rq_throttled;\n",
      "}\n",
      "\n",
      "/**\n",
      " * worker_clr_flags(worker, WORKER_PREP);\n",
      "sleep:\n",
      "\t/*\n",
      "\t * In the semi idle case by checking on the CPU, it can't propagate the requeue\n",
      " * @mode:\texpiry mode: absolute time */\n",
      "\tif (ftrace_enabled) {\n",
      "\t\t/* Keep track of cpu being initialization of architecture-specific fields. */\n",
      "\tadd_taint(TAINT_LIVEPATCH\\n\");\n",
      "\tadd_taint(TAINT_FORCED_MODULE))\n",
      "\t\tbuf[l++] = 'E';\n",
      "\n",
      "\trwbs[i] = '\\0';\n",
      "\tif (count > 0) {\n",
      "\t\terror = -EINVAL;\n",
      "\t}\n",
      "\n",
      "\tif (prctl_map->__m1 __op\t\t\t\t\\\n",
      "\t (unsigned long ticks)\n",
      "{\n",
      "\tjiffie\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=10)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/timer.c.\n",
      " *  Please see that file for copyright and history logs.\n",
      " *\n",
      " */\n",
      "\n",
      "#include <linux/slab.h>\n",
      "#include <linux/kernel.h>\n",
      "#include <linux/sysrq.h>\n",
      "#include <linux/fs.h>\n",
      "#include <linux/sched/sysctl.h>\n",
      "#include <linux/percpu-rwsem.h>\n",
      "#include <linux/utsname.h>\n",
      "#include <linux/hardirq.h>\n",
      "#include <linux/tty.h>\n",
      "#include <linux/hardirq.h>\n",
      "#include <linux/irq.h>\n",
      "#include <linux/atomic.h>\n",
      "#include <linux/skbuff.h>\n",
      "#ifdef CONFIG_DEBUG_OBJECTS_RCU_HEAD kernel builds.\n",
      " */\n",
      "void destroy_rcu_head_on_stack(&rh1);\n",
      "\tinit_rcu_head_on_stack(&rcu.head);\n",
      "\tinit_completion(&self.exited);\n",
      "\tinit_completion(&rcu.completion);\n",
      "\n",
      "\t/* Other rcu_barrier(). */\n",
      "\t/* End of fields guarded by barrier_mutex. */\n",
      "\n",
      "\tatomic_long_t refs;\n",
      "\tstruct rcu_node *rnp;\n",
      "\n",
      "\tif (t->rcu_read_lock_nesting, shared state will be updated only when filter_hash updating */\n",
      "\t\tret = atomic_add_return(1, &rttest_event);\n",
      "\t\ttd->mutexes[td->opdata] = 1;\n",
      "\t\ttd->event = atomic_add_return(0, &rdp->dynticks->dynticks_nesting, rdtp->dyn\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=15)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/manage.c\n",
      " *\n",
      " * Copyright (C) 2006 Timesys Corp., Thomas Gleixner\n",
      " *\n",
      " * This code is licenced under the GPL version 2. For details see\n",
      " * kernel-base/COPYING\n",
      " */\n",
      "\n",
      "#include <linux/mm.h>\n",
      "#include <linux/binfmts.h>\n",
      "#include <linux/spinlock.h>\n",
      "#include <linux/sched.h> /* for spin_unlock_irq() using preempt_count() m68k */\n",
      "#include <linux/types.h>\n",
      "#include <linux/mutex.h>\n",
      "#include <linux/fs.h>\n",
      "#include <linux/module.h>\n",
      "#include <linux/nfs_fs.h>\n",
      "#include <linux/percpu.h>\n",
      "#include <linux/slab.h>\n",
      "\n",
      "#include \"power.h\"\n",
      "\n",
      "static DEFINE_MUTEX(stop_cpus_mutex);\n",
      "static DEFINE_SPINLOCK(rcu_torture_lock);\n",
      "static DEFINE_PER_CPU(struct llist_head, call_single_queue);\n",
      "\n",
      "static void flush_module_icache(const struct module *mod,\n",
      "\t\t\t const unsigned long seccomp_mode = SECCOMP_MODE_STRICT:\n",
      "\t\top = SECCOMP_SET_MODE_FILTER:\n",
      "\t\treturn __seccomp_phase1_filter(int this_syscall, struct seccomp_data *sd)\n",
      "{\n",
      "\tstruct seccomp_filter *walker;\n",
      "\n",
      "\tassert_spin_locked(&current->sighand->siglock);\n",
      "\tset_proces\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=20)\n",
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/autoprobe.c\n",
      " *\n",
      " * Copyright (C) 2003-2004 Amit S. Kale <amitkale@linsyssoft.com>\n",
      " * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.\n",
      " *\n",
      " * This program is free software; you can redistribute it and/or modify\n",
      " * it under the terms of the GNU General Public License version 2 as\n",
      " * published by the Free Software Foundation.\n",
      " */\n",
      "\n",
      "#include <linux/sched/rt.h>\n",
      "\n",
      "#include \"trace.h\"\n",
      "#include \"trace_output.h\"\n",
      "\n",
      "struct header_iter {\n",
      "\tstruct pci_dev *dev;\n",
      "};\n",
      "\n",
      "static struct rb_root swsusp_extents = RB_ROOT;\n",
      "\n",
      "static int swsusp_page_is_forbidden(page) && swsusp_page_is_free(virt_to_page(lp))) {\n",
      "\t\t\t/* The page is \"safe\", add it to the list */\n",
      "\t\t\tlp->next = safe_pages_list;\n",
      "\t\tsafe_pages_list = safe_pages_list->next;\n",
      "\tpbe->next = restore_pblist;\n",
      "\trestore_pblist = NULL;\n",
      "\tbuffer = NULL;\n",
      "\talloc_normal = 0;\n",
      "\talloc_highmem = 0;\n",
      "\n",
      "\t/* Count the number of saveable data pages. */\n",
      "\tsave_highmem = count_highmem_image_pages - compute the total number of overruns from\n",
      " */\n",
      "unsigned long\n",
      "ring\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/resend.c\n",
      " *\n",
      " * Copyright (C) 1997  Andrew Main <zefram@fysh.org>\n",
      " *\n",
      " * Integrated into 2.1.97+,  Andrew G. Morgan <morgan@kernel.org>\n",
      " * 30 May 2002:\tCleanup, Robert M. Love <rml@tech9.net>\n",
      " */\n",
      "\n",
      "#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n",
      "\n",
      "#include <linux/module.h>\n",
      "#include <linux/slab.h>\n",
      "#include \"cpudeadline.h\"\n",
      "#include \"cpuacct.h\"\n",
      "\n",
      "struct rq;\n",
      "struct cpuidle_state *idle_state)\n",
      "{\n",
      "\trq->idle_state = idle_state;\n",
      "}\n",
      "\n",
      "static inline struct cpuacct *css_ca(struct cgroup_subsys *ss;\n",
      "\tint i;\n",
      "\n",
      "\tinit_cgroup_root(&cgrp_dfl_root, &opts);\n",
      "\tcgrp_dfl_root.cgrp.self.flags |= CSS_NO_REF;\n",
      "\n",
      "\tif (early) {\n",
      "\t\t/* allocation can't be done safely during early init */\n",
      "\t\tcss->id = 1;\n",
      "\t} else {\n",
      "\t\tcss->id = cgroup_idr_alloc(&ss->css_idr, css, 1, 2,\n",
      "\t\t\t\t\t\t   GFP_KERNEL);\n",
      "\tif (!data)\n",
      "\t\tgoto out;\n",
      "\n",
      "\tcd->fp = fp;\n",
      "\tcd->clk = get_posix_clock(fp);\n",
      "\tint err = -ENODEV;\n",
      "\n",
      "\tif (cnt >= PAGE_SIZE)\n",
      "\t\treturn -EINVAL;\n",
      "\trcu_read_lock();\n",
      "\tsd = rcu_dereference(per_cpu(sd_asym, cpu), sd);\n",
      "}\n",
      "\n",
      "/*\n",
      " * Attach the domain 'sd' to 'cpu' as its base domain. Callers must\n",
      " * hold the hotplug lock.\n",
      " * For now this just excludes isolated cpus, but could be used to\n",
      " * exclude other special cases in the future.\n",
      " */\n",
      "void nohz_balance_enter_idle(int cpu)\n",
      "{\n",
      "\t/*\n",
      "\t * Make sure legacy kernel users don't send in bad values\n",
      "\t * (normal paths check this in check_kill_permission(int sig, struct k_sigaction *ka;\n",
      "\n",
      "\t\tif (unlikely(current->lockdep_recursion = 1;\n",
      "\t__trace_hardirqs_on_caller(CALLER_ADDR0);\n",
      "}\n",
      "EXPORT_SYMBOL(default_wake_function(wait, mode, sync, key);\n",
      "}\n",
      "\n",
      "void __wake_up_parent(struct task_struct *\n",
      "pick_next_task_stop(struct rq *rq)\n",
      "{\n",
      "}\n",
      "\n",
      "static inline void dl_clear_overload(struct rq *rq)\n",
      "{\n",
      "\treturn atomic_read(&mod->refcnt) - MODULE_REF_BASE;\n",
      "}\n",
      "EXPORT_SYMBOL(mod_timer_pinned);\n",
      "\n",
      "/**\n",
      " * add_timer - start a timer\n",
      " * @timer: the timer to be initialized\n",
      " *\n",
      " * This function can be called from any context.\n",
      " */\n",
      "void audit_log_untrustedstring(ab, get_task_comm(comm, current));\n",
      "\taudit_log_untrustedstring(ab, get_task_comm(comm, tsk));\n",
      "\n",
      "\taudit_log_d_path_exe(struct audit_buffer *ab, __u32 portid)\n",
      "{\n",
      "\tif (ab) {\n",
      "\t\tstruct nlmsghdr *nlh;\n",
      "\t/*\n",
      "\t * len MUST be signed for nlmsg_next to be able to dec it below 0\n",
      "\t * if the nlmsg_len was not aligned\n",
      "\t */\n",
      "\tint len;\n",
      "\tint err;\n",
      "\n",
      "\tnlh = nlmsg_put(ab->skb, 0, 0, type, 0, 0);\n",
      "\tif (!nlh)\n",
      "\t\tgoto out_kfree_skb;\n",
      "\n",
      "\treturn ab;\n",
      "\n",
      "out_kfree_skb:\n",
      "\tkfree_skb(skb);\n",
      "\treturn NULL;\n",
      "}\n",
      "\n",
      "static struct ftrace_ops global_ops = {\n",
      "\t.func\t\t\t= event_enable_count_trigger_ops = {\n",
      "\t.func\t\t\t= ftrace_traceon_print,\n",
      "};\n",
      "\n",
      "static struct kobj_attribute *attr,\n",
      "\t\t\t   char *buf)\n",
      "{\n",
      "\treturn sprintf(buffer, \"%i\\n\", module_refcount(mod));\n",
      "\n",
      "\t/*\n",
      "\t * Always include a trailing , so userspace can differentiate\n",
      "\t * between this and the old multi-field proc format.\n",
      "\t */\n",
      "\tlist_for_each_entry(tr, &ftrace_trace_arrays, list) {\n",
      "\t\tlist_for_each_entry(event, &parent_ctx->pinned_groups, group_entry) {\n",
      "\t\tret = inherit_task_group(event, parent, parent_ctx,\n",
      "\t\t\t    child, child_ctx);\n",
      "\n",
      "\tif (ret)\n",
      "\t\t*inherited_all = 0;\n",
      "\t\treturn 0;\n",
      "\t}\n",
      "\t\n",
      "\ti = (int *) tbl_data;\n",
      "\tvleft = table->maxlen / sizeof(*i);\n",
      "\tleft = *lenp;\n",
      "\n",
      "\tif (!conv)\n",
      "\t\tconv = do_proc_dointvec_conv;\n",
      "\n",
      "\tif (write) {\n",
      "\t\tif (sysctl_writes_strict = SYSCTL_WRITES_WARN)\n",
      "\t\twarn_sysctl_write(table);\n",
      "\t\t\t\tbreak;\n",
      "\t\t\tdefault:\n",
      "\t\t\t\tWARN_ON_ONCE(1);\n",
      "\t\treturn PTR_ERR(old);\n",
      "\t}\n",
      "\n",
      "\tif (!tp_funcs) {\n",
      "\t\t/* Removed last function */\n",
      "\t\tif (tp->unregfunc && static_key_enabled(key);\n",
      "\n",
      "\tif ((!true_branch && state) || (true_branch && !state))\n",
      "\t\treturn JUMP_LABEL_ENABLE;\n",
      "\n",
      "\treturn JUMP_LABEL_DISABLE;\n",
      "}\n",
      "\n",
      "void __init jump_label_init(void)\n",
      "{\n",
      "\tstruct dentry *d = kern_path_locked(watch->path, parent);\n",
      "\tif (IS_ERR(tg))\n",
      "\t\treturn ERR_PTR(-ENOTDIR);\n",
      "\tctl_name = *name;\n",
      "\tname++;\n",
      "\tnlen--;\n",
      "\tfor ( ; table->convert; table++) {\n",
      "\t\tint len = 0;\n",
      "\n",
      "\t\t/*\n",
      "\t\t * For a wild card entry map from ifindex to network\n",
      "\t\t * device name.\n",
      "\t\t */\n",
      "\t\tif (!table->ctl_name) {\n",
      "#ifdef CONFIG_NET\n",
      "\t.net_ns\t\t\t= &init_net,\n",
      "#endif\n",
      "};\n",
      "\n",
      "static struct miscdevice snapshot_device = {\n",
      "\t.minor = SNAPSHOT_MINOR,\n",
      "\t.name = \"snapshot\",\n",
      "\t.fops = &snapshot_fops,\n",
      "};\n",
      "\n",
      "static int __init sched_clock_postinit(void)\n",
      "{\n",
      "\t/*\n",
      "\t * If there is an existing filter, make it the prev and don't drop its\n",
      "\t * task reference.\n",
      "\t */\n",
      "\tfilter->prev = current->seccomp.mode && current->seccomp.mode != seccomp_mode)\n",
      "\t\treturn false;\n",
      "\n",
      "\tif ((sgs->group_capacity * 100) >\n",
      "\t\t\t(sgs->group_usage * env->sd->imbalance_pct))\n",
      "\t\treturn true;\n",
      "\n",
      "\treturn false;\n",
      "}\n",
      "\n",
      "static bool klp_initialized(void)\n",
      "{\n",
      "\treturn klp_root_kobj;\n",
      "}\n",
      "\n",
      "struct klp_find_arg *args = data;\n",
      "\n",
      "\tif (!mod &&\n",
      "\t    !strcmp(args->name, name) &&\n",
      "\t    args->addr == addr)\n",
      "\t\treturn 1;\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static struct ftrace_ops *ops)\n",
      "{\n",
      "\tint __percpu *disabled;\n",
      "\n",
      "\tdisabled = alloc_percpu(int);\n",
      "\tif (!disabled)\n",
      "\t\treturn -EINVAL;\n",
      "\n",
      "\tif (vma_size != PAGE_SIZE * (1 + nr_pages))\n",
      "\t\treturn -EINVAL;\n",
      "\t}\n",
      "\tif (insn->off != 0) {\n",
      "\t\t\t\tverbose(\"BPF_END uses reserved fields\\n\");\n",
      "\t\t\t\treturn -EINVAL;\n",
      "\t\t}\n",
      "\t\tp[AUDIT_WORD(n)] |= AUDIT_BIT(n);\n",
      "\t}\n",
      "\tif (class >= AUDIT_SYSCALL_CLASSES) {\n",
      "\t\t\tkfree(p);\n",
      "\t\t\treturn -EINVAL;\n",
      "\t/* FALL THROUGH */\n",
      "\tcase AUDIT\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(lm, length=5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Order 10 is pretty much junk. In order 15 things sort-of make sense, but we jump abruptly between the `[sic]`\n",
    "and by order 20 we are doing quite nicely â€” but are far from keeping good indentation and brackets. \n",
    "\n",
    "How could we? we do not have the memory, and these things are not modeled at all. While we could quite easily enrich our model to support also keeping track of brackets and indentation (by adding information such as \"have I seen ( but not )\" to the conditioning history), this requires extra work, non-trivial human reasoning, and will make the model significantly more complex. \n",
    "\n",
    "Karpathy's LSTM, on the other hand, seemed to have just learn it on its own. And that's impressive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
